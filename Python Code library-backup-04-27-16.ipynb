{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@python\n",
    "numba.__version__\n",
    "'0.25.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read from file\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "expedia_pred3 = pd.read_csv('preds3rf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#profile \n",
    "print(train.head())\n",
    "#explore a DataFrame using the .describe()\n",
    "#.shape attribute of your DataFrame object. (ex. your_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#deeper exploration\n",
    "#factors\n",
    "print(train[\"Survived\"].value_counts())  #counts by factor\n",
    "print(train[\"Survived\"].value_counts(normalize = True))   # proportions\n",
    "\n",
    "#factors-subet\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts()) # Females that survived vs Females that passed away\n",
    "print(train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True))  # proportion and subset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new variables\n",
    "your_data[\"new_var\"] = 10   # 10 for each observation\n",
    " #(i) create a new column, and \n",
    "    #(ii) provide the values for each observation (i.e., row) based on the age of the passenger.\n",
    "#example    \n",
    "train[\"Child\"] = float('NaN')\n",
    "train.Child[train.Age < 18] = 1\n",
    "train.Child[train.Age >= 18] = 0\n",
    "print(train.Child)\n",
    "\n",
    "\n",
    "# Initialize a Survived column to 0\n",
    "test_one[\"Survived\"] = 0\n",
    "# Set Survived to 1 if Sex equals \"female\" and print the `Survived` column from `test_one`\n",
    "test_one[\"Survived\"][train[\"Sex\"] == \"female\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning/imputing\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "#Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "\n",
    "test.Fare[152] = test.Fare.median()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transformation\n",
    "#Convert the male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "\n",
    "#Convert the Embarked classes to integer form\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "#Print the Sex and Embarked columns\n",
    "print(train[\"Sex\"])\n",
    "print(train[\"Embarked\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature-engineering \n",
    "\n",
    "combining variables with the same unit and binning them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the Numpy library\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "methods take numpy arrays as inputs and therefore we will need to create those from the DataFrame that we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target: A one-dimensional numpy array containing the target/response from the train data.\n",
    "\n",
    "# features: A multidimensional numpy array containing the features/predictors from the train data.\n",
    "target = train[\"Survived\"].values\n",
    "\n",
    "features = train[[\"Sex\", \"Age\"]].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c29d978f0871>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c29d978f0871>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    .feature_importances_ #importance: requesting the\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#decision trees -- Import 'tree' from scikit-learn library\n",
    "from sklearn import tree\n",
    "\n",
    "#training\n",
    "\n",
    "my_tree = tree.DecisionTreeClassifier()\n",
    "my_tree = my_tree.fit(features, target)\n",
    "\n",
    "#analysis & testing:\n",
    "\n",
    ".feature_importances_ #importance: requesting the \n",
    ".score() # mean accuracy that you can compute using the\n",
    "\n",
    "    print(my_tree_one.feature_importances_)\n",
    "print(my_tree_one.score(features_one, target))\n",
    "clf.score(features_test,labels_test)\n",
    "\n",
    "#control overfitting\n",
    "# DecisionTreeRegressor\n",
    "#, the depth of our model is defined by two parameters: \n",
    "#    - the max_depth parameter determines when the splitting up of the decision tree stops. \n",
    "#    - the min_samples_split parameter monitors the amount of observations in a bucket. \n",
    "#If a certain threshold is not reached (e.g minimum 10 passengers) no further splitting can be done.\n",
    "#By limiting the complexity of your decision tree you will increase its generality and thus its usefulness for prediction!\n",
    "\n",
    "# Create a new array with the added features: features_two\n",
    "features_two = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "# Control overfitting by setting \"max_depth\" to 10 and \"min_samples_split\" to 5 : my_tree_two\n",
    "max_depth = 10\n",
    "min_samples_split = 5\n",
    "my_tree_two = tree.DecisionTreeClassifier(max_depth = 10, min_samples_split = 5, random_state = 1)\n",
    "\n",
    "\n",
    "#2-D plotting\n",
    "%pylab inline\n",
    "import sys #?\n",
    "import matplotlib.pyplot as plt #?\n",
    "import numpy as np #?\n",
    "import pylab as pl #?\n",
    "sys.path.append('../tools') #?\n",
    "Populating the interactive namespace from numpy and matplotlib #?\n",
    "from class_vis import prettyPicture, output_image\n",
    "from prep_terrain_data import makeTerrainData\n",
    "\n",
    "prettyPicture(clf, features_test, labels_test)\n",
    "# output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "#handles the overfitting problem you faced with decision trees. \n",
    "#grows multiple (very deep) classification trees using the training set.\n",
    "# each tree is used to come up with a prediction and every outcome is counted as a vote\n",
    "# majority's vote count as the actual classification decision, avoids overfitting.\n",
    "\n",
    "#n_estimators=allows you to set the number of trees you wish to plant and average over.\n",
    "\n",
    "\n",
    "#Import the `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#We want the Pclass, Age, Sex, Fare,SibSp, Parch, and Embarked variables\n",
    "features_forest = train[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "#Building the Forest: my_forest\n",
    "n_estimators = 100\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators=100, random_state = 1)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "\n",
    "#Print the score of the random forest\n",
    "print(my_forest.score(features_forest, target))\n",
    "\n",
    "#Compute predictions and print the length of the prediction vector:test_features, pred_forest\n",
    "test_features = test[[\"Pclass\",\"Age\",\"Sex\",\"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "pred_forest = my_forest.predict(test_features)\n",
    "print(len(pred_forest))\n",
    "\n",
    "\n",
    "#feature importances and score\n",
    "\n",
    "#Request and print the `.feature_importances_` attribute\n",
    "print(my_tree_two.feature_importances_)\n",
    "print(my_forest.feature_importances_)\n",
    "\n",
    "#Compute and print the mean accuracy score for both models\n",
    "print(my_tree_two.score(features_two, target))\n",
    "print(my_forest.score(features_two, target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test mining\n",
    "http://napitupulu-jon.appspot.com/posts/decision-tree-ud.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python-Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Numpy-Linear Algebra/Arrays\n",
    "\n",
    "http://scipy.github.io/old-wiki/pages/Tentative_NumPy_Tutorial.html#A.22Automatic.22_Reshaping \n",
    "\n",
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# you can create a 1-d array with a list of numbers\n",
    "a = np.array([1, 4, 6])\n",
    "print np.ones((3, 4))\n",
    "print np.zeros((2, 5))\n",
    "\n",
    "#Transpose matrix\n",
    "print b.T\n",
    "\n",
    "#Inverse a matrix\n",
    "m_inverse = np.linalg.inv(m)\n",
    "\n",
    "# you can convert a 1-d array to a 2-d array with np.newaxis\n",
    "(3,)-> a[np.newaxis].shape: (1, 3)\n",
    "\n",
    "#reshape\n",
    "\n",
    "#concate arrays\n",
    "np.hstack([b, b]):\n",
    "np.vstack([b, b]):\n",
    "\n",
    "#matrix multiplication\n",
    "# you can perform matrix multiplication with np.dot()\n",
    "c = np.dot(a, b)\n",
    "\n",
    "# you can perform element-wise multiplication with * \n",
    "d = b * b\n",
    "\n",
    "#decision stuctures\n",
    "\n",
    "for this_row in b:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pandas-Scientific Computing/Data Frames\n",
    "http://pandas-docs.github.io/pandas-docs-travis/ \n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(data=b,  columns=['Weight', 'Height'])\n",
    "\n",
    "\n",
    "# read .csv files\n",
    "baseball = pd.read_csv('data/baseball.dat.txt')\n",
    "\n",
    "# save .csv files\n",
    "\n",
    "\n",
    "## expore data\n",
    "\n",
    "baseball.head()  \t#first five rows\n",
    "baseball.keys()  \t\t# column name, and data\n",
    "baseball.info()\t\t\t# column data type, and no. of rows \n",
    "Salary                     337 non-null int64\n",
    "baseball.describe()\t\t#summary of mean, sd, count and percentiles\n",
    "\n",
    "# Query data\n",
    "millionaire_indices = baseball['Salary'] > 1000\t\t\t\t\t   # filter\n",
    "print (\"baseball[millionaire_indices].shape:\", baseball[millionaire_indices].shape)    # by column\n",
    "baseball[millionaire_indices][['Salary', 'AVG', 'Runs', 'Name']]\t                   #subset by column\n",
    "\n",
    "\n",
    "#joins\n",
    "merged = pd.merge(baseball, shoe_size_df, on=['Name'])\n",
    "merged_outer = pd.merge(baseball, shoe_sizes, on=['Name'], how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Presentation\n",
    "\n",
    "#display image from pc\n",
    "from IPython.display import Image\n",
    "Image('decision-tree-ud_files/4.jpg')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
